# CoInception å¯è§†åŒ–å¤ç°ä¼˜åŒ–åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ¦‚è¿°

æœ¬æŠ¥å‘Šå¯¹ç…§è®ºæ–‡ "Improving Time Series Encoding with Noise-Aware Self-Supervised Learning and an Efficient Encoder" (arXiv:2306.06579v3) åˆ†æå½“å‰å®ç°çš„å¯è§†åŒ–æ•ˆæœï¼Œå¹¶æä¾›å…·ä½“ä¼˜åŒ–å»ºè®®ã€‚

---

## ğŸ” ä¸€ã€å½“å‰å®ç°ä¸è®ºæ–‡å¯¹æ¯”

### å½“å‰å¯è§†åŒ–æ–‡ä»¶

| æ–‡ä»¶ | å†…å®¹ | è®ºæ–‡å¯¹åº” | è¯„ä¼° |
|------|------|----------|------|
| `similarity_matrix.png` | ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ (out1, out1s, out2, out2s) | - | âš ï¸ ç¼ºå°‘ä¸TS2Vecå¯¹æ¯” |
| `representation_tsne.png` | t-SNEå¯è§†åŒ– | Fig.6, 14 | âŒ ç¼ºå°‘ç±»åˆ«ç€è‰² |
| `representation_pca.png` | PCAå¯è§†åŒ– | - | âš ï¸ éœ€æ·»åŠ ç±»åˆ«ä¿¡æ¯ |
| `loss_history.png` | è®­ç»ƒæŸå¤±æ›²çº¿ | - | âœ… è‰¯å¥½ |
| `loss_heatmap.png` | æŸå¤±ç»„ä»¶çƒ­åŠ›å›¾ | - | âœ… è‰¯å¥½ |
| `representations.png` | ç›¸ä¼¼åº¦åˆ†å¸ƒç›´æ–¹å›¾ | Fig.5 | âš ï¸ åº”æ”¹ä¸ºL2è·ç¦» |

### è®ºæ–‡æ ¸å¿ƒå¯è§†åŒ–ç¼ºå¤±é¡¹

| è®ºæ–‡å›¾è¡¨ | æè¿° | é‡è¦æ€§ | å½“å‰çŠ¶æ€ |
|----------|------|--------|----------|
| **Figure 2** | å™ªå£°é²æ£’æ€§å¯¹æ¯” (æ ¸å¿ƒåˆ›æ–°!) | ğŸ”´ æé«˜ | âŒ å®Œå…¨ç¼ºå¤± |
| **Figure 5** | å¯¹é½æ€§åˆ†æ (L2è·ç¦»ç›´æ–¹å›¾) | ğŸ”´ é«˜ | âš ï¸ ç”¨é”™äº†æŒ‡æ ‡ |
| **Figure 6** | å‡åŒ€æ€§åˆ†æ (KDEå¯†åº¦å›¾) | ğŸ”´ é«˜ | âŒ å®Œå…¨ç¼ºå¤± |
| **Figure 8** | å™ªå£°æ¯”ä¾‹åˆ†æ (é›·è¾¾å›¾) | ğŸŸ¡ ä¸­ | âŒ å®Œå…¨ç¼ºå¤± |
| **Figure 13** | æ„Ÿå—é‡åˆ†æ | ğŸŸ¡ ä¸­ | âŒ å®Œå…¨ç¼ºå¤± |
| **Figure 14** | èšç±»æ€§åˆ†æ (å¸¦ç±»åˆ«t-SNE) | ğŸ”´ é«˜ | âš ï¸ ç¼ºå°‘ç±»åˆ«ä¿¡æ¯ |

---

## ğŸš¨ äºŒã€å…³é”®é—®é¢˜è¯Šæ–­

### é—®é¢˜1: t-SNE/PCAå¯è§†åŒ–ç¼ºé™·

**å½“å‰é—®é¢˜:**
```
å½“å‰ representation_tsne.png æ˜¾ç¤ºçš„æ˜¯:
- out1 (è“è‰²) 
- out1s (çº¢è‰²)
- out2 (ç²‰è‰²)
- out2s (é’è‰²)

è¿™åªæ˜¯encoderçš„ä¸åŒè¾“å‡ºç±»å‹ï¼Œè€Œéæ ·æœ¬çš„çœŸå®ç±»åˆ«!
```

**è®ºæ–‡è¦æ±‚ (Figure 14):**
- åº”è¯¥æŒ‰æ ·æœ¬çš„ground truthç±»åˆ«ç€è‰²
- åŒä¸€ç±»åˆ«çš„ç‚¹åº”èšé›†åœ¨ä¸€èµ·
- éœ€è¦ä¸TS2Vecè¿›è¡Œå¯¹æ¯”å±•ç¤º

**è§£å†³æ–¹æ¡ˆ:**
```python
# è®­ç»ƒæ—¶ä¿å­˜ç±»åˆ«ä¿¡æ¯
def save_representations_with_labels(model, dataloader, save_path):
    representations = []
    labels = []
    for x, y in dataloader:
        z = model.encoder(x)
        representations.append(z.cpu().numpy())
        labels.append(y.cpu().numpy())  # ä¿å­˜çœŸå®æ ‡ç­¾
    
    np.savez(save_path, 
             representations=np.concatenate(representations),
             labels=np.concatenate(labels))
```

### é—®é¢˜2: å™ªå£°é²æ£’æ€§åˆ†æå®Œå…¨ç¼ºå¤± (è®ºæ–‡æ ¸å¿ƒ!)

**è®ºæ–‡Figure 2çš„æ ¸å¿ƒä¿¡æ¯:**
- Noiseless vs Noisyä¿¡å·å¯¹æ¯”
- CoInceptionç›¸å…³æ€§: **0.983**
- TS2Vecç›¸å…³æ€§: **0.837**
- è¿™æ˜¯è®ºæ–‡çš„**ä¸»è¦åˆ›æ–°ç‚¹**ï¼Œå¿…é¡»å¤ç°!

**è§£å†³æ–¹æ¡ˆ:**
```python
def test_noise_robustness(model, x):
    """æµ‹è¯•å™ªå£°é²æ£’æ€§"""
    # ç”Ÿæˆå¸¦å™ªå£°ç‰ˆæœ¬
    x_noisy = x + 0.3 * torch.randn_like(x)
    
    # è·å–è¡¨å¾
    z_clean = model.encoder(x)
    z_noisy = model.encoder(x_noisy)
    
    # è®¡ç®—ç›¸å…³æ€§
    correlation = torch.nn.functional.cosine_similarity(
        z_clean.flatten(), z_noisy.flatten(), dim=0
    )
    return correlation.item()
```

### é—®é¢˜3: ç›¸ä¼¼åº¦åˆ†å¸ƒä½¿ç”¨é”™è¯¯æŒ‡æ ‡

**å½“å‰é—®é¢˜:**
- `representations.png` æ˜¾ç¤ºä½™å¼¦ç›¸ä¼¼åº¦åˆ†å¸ƒ
- è®ºæ–‡Figure 5è¦æ±‚çš„æ˜¯**L2è·ç¦»**åˆ†å¸ƒ

**è§£å†³æ–¹æ¡ˆ:**
```python
def compute_l2_distances(z_anchor, z_positive):
    """è®¡ç®—æ­£æ ·æœ¬å¯¹çš„L2è·ç¦»"""
    l2_dist = torch.norm(z_anchor - z_positive, p=2, dim=-1)
    return l2_dist.cpu().numpy()
```

---

## ğŸ“Š ä¸‰ã€è®­ç»ƒé…ç½®è¯„ä¼°

å½“å‰é…ç½® (æ¥è‡ª `robustness_report.txt`):

| å‚æ•° | å½“å‰å€¼ | è®ºæ–‡å‚è€ƒ | è¯„ä¼° |
|------|--------|----------|------|
| n_epochs | 100 | ç±»ä¼¼ | âœ… |
| n_iters | 200 | ç±»ä¼¼ | âœ… |
| batch_size | **8** | é€šå¸¸æ›´å¤§ | âš ï¸ |
| lr | 0.001 | 0.001 | âœ… |
| max_train_length | 3000 | 3000 | âœ… |
| æŸå¤±æ”¹å–„ | 89.77% | - | âœ… |

**æ½œåœ¨é—®é¢˜:**
- batch_size=8 å¯èƒ½åå°ï¼Œå»ºè®®å°è¯• 16 æˆ– 32
- åªä¿å­˜äº†2ä¸ªæ—¶é—´ç‚¹çš„è¡¨å¾ï¼Œå»ºè®®å¢åŠ é‡‡æ ·é¢‘ç‡

---

## ğŸ›  å››ã€ä¼˜åŒ–å»ºè®®ä¼˜å…ˆçº§

### P0 (ç´§æ€¥ï¼Œå½±å“è®ºæ–‡æ ¸å¿ƒéªŒè¯)

1. **å®ç°å™ªå£°é²æ£’æ€§å¯è§†åŒ– (Figure 2)**
   - é¢„è®¡å·¥ä½œé‡: 4å°æ—¶
   - è¿™æ˜¯è®ºæ–‡çš„**æ ¸å¿ƒåˆ›æ–°**ï¼Œå¿…é¡»å®ç°
   - éœ€è¦ç”Ÿæˆåˆæˆå™ªå£°ä¿¡å·å¹¶è®¡ç®—è¡¨å¾ç›¸å…³æ€§

2. **ä¿®å¤t-SNEæ·»åŠ ç±»åˆ«æ ‡ç­¾ (Figure 14)**
   - é¢„è®¡å·¥ä½œé‡: 2å°æ—¶
   - ä¿®æ”¹è®­ç»ƒè„šæœ¬ä¿å­˜æ ·æœ¬æ ‡ç­¾
   - æŒ‰ç±»åˆ«ç€è‰²è€Œéencoderè¾“å‡ºç±»å‹

### P1 (é‡è¦ï¼Œå±•ç¤ºè¡¨å¾è´¨é‡)

3. **æ·»åŠ å¯¹é½æ€§åˆ†æ (Figure 5)**
   - é¢„è®¡å·¥ä½œé‡: 3å°æ—¶
   - å°†ä½™å¼¦ç›¸ä¼¼åº¦æ”¹ä¸ºL2è·ç¦»
   - æ·»åŠ å‡å€¼çº¿æ ‡æ³¨

4. **æ·»åŠ å‡åŒ€æ€§åˆ†æ (Figure 6)**
   - é¢„è®¡å·¥ä½œé‡: 4å°æ—¶
   - å®ç°Gaussian KDEå¯†åº¦å›¾
   - å®ç°vMF KDEè§’åº¦åˆ†å¸ƒ

### P2 (è¡¥å……ï¼Œå®Œæ•´å¤ç°)

5. **æ·»åŠ å™ªå£°æ¯”ä¾‹åˆ†æ (Figure 8)**
   - é¢„è®¡å·¥ä½œé‡: 2å°æ—¶
   - å®ç°é›·è¾¾å›¾å¯è§†åŒ–

6. **æ·»åŠ æ„Ÿå—é‡åˆ†æ (Figure 13)**
   - é¢„è®¡å·¥ä½œé‡: 2å°æ—¶
   - å¯ç›´æ¥ä½¿ç”¨è®ºæ–‡å…¬å¼è®¡ç®—

### P3 (å¯é€‰ï¼Œå¢å¼ºå¯¹æ¯”)

7. **æ·»åŠ TS2VecåŸºçº¿å¯¹æ¯”**
   - é¢„è®¡å·¥ä½œé‡: 8å°æ—¶
   - éœ€è¦è¿è¡ŒTS2Vecè·å–å¯¹æ¯”æ•°æ®

---

## ğŸ“ äº”ã€ä»£ç ä¿®æ”¹å»ºè®®

### 5.1 ä¿®æ”¹è®­ç»ƒè„šæœ¬ä¿å­˜æ ‡ç­¾

```python
# åœ¨ train.py ä¸­æ·»åŠ 
def save_training_artifacts(model, dataloader, epoch, save_dir):
    """ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„artifactsç”¨äºå¯è§†åŒ–"""
    model.eval()
    
    all_representations = {'out1': [], 'out1s': [], 'out2': [], 'out2s': []}
    all_labels = []
    
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            out1, out1s, out2, out2s = model.encoder(x, return_all=True)
            
            all_representations['out1'].append(out1.cpu())
            all_representations['out1s'].append(out1s.cpu())
            all_representations['out2'].append(out2.cpu())
            all_representations['out2s'].append(out2s.cpu())
            all_labels.append(y)  # ä¿å­˜æ ‡ç­¾!
    
    # åˆå¹¶å¹¶ä¿å­˜
    save_data = {
        'out1': torch.cat(all_representations['out1']).numpy(),
        'out1s': torch.cat(all_representations['out1s']).numpy(),
        'out2': torch.cat(all_representations['out2']).numpy(),
        'out2s': torch.cat(all_representations['out2s']).numpy(),
        'labels': torch.cat(all_labels).numpy()  # åŒ…å«æ ‡ç­¾
    }
    
    np.save(f'{save_dir}/representations_epoch_{epoch}.npy', save_data)
```

### 5.2 æ·»åŠ å™ªå£°é²æ£’æ€§æµ‹è¯•

```python
def evaluate_noise_robustness(model, dataloader, noise_levels=[0.1, 0.2, 0.3]):
    """è¯„ä¼°æ¨¡å‹çš„å™ªå£°é²æ£’æ€§"""
    model.eval()
    results = {}
    
    for noise_level in noise_levels:
        correlations = []
        
        with torch.no_grad():
            for x, _ in dataloader:
                x = x.to(device)
                
                # æ·»åŠ å™ªå£°
                x_noisy = x + noise_level * torch.randn_like(x)
                
                # è·å–è¡¨å¾
                z_clean = model.encoder(x)
                z_noisy = model.encoder(x_noisy)
                
                # è®¡ç®—ç›¸å…³æ€§
                for i in range(z_clean.size(0)):
                    corr = F.cosine_similarity(
                        z_clean[i].flatten().unsqueeze(0),
                        z_noisy[i].flatten().unsqueeze(0)
                    ).item()
                    correlations.append(corr)
        
        results[f'noise_{int(noise_level*100)}%'] = {
            'mean_corr': np.mean(correlations),
            'std_corr': np.std(correlations)
        }
    
    return results
```

### 5.3 ä¿®æ­£å¯è§†åŒ–è„šæœ¬

```python
def visualize_tsne_with_labels(representations, labels, save_path):
    """è®ºæ–‡é£æ ¼çš„t-SNEå¯è§†åŒ–"""
    from sklearn.manifold import TSNE
    
    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, random_state=42, perplexity=30)
    embeddings_2d = tsne.fit_transform(representations)
    
    # æŒ‰ç±»åˆ«ç€è‰²
    unique_labels = np.unique(labels)
    colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    for label, color in zip(unique_labels, colors):
        mask = labels == label
        ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],
                  c=[color], label=f'Class {label}', alpha=0.7, s=30)
    
    ax.legend()
    ax.set_title('t-SNE Visualization (by Ground Truth Labels)')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
```

---

## ğŸ“ˆ å…­ã€å½“å‰å¤ç°å®Œæˆåº¦è¯„ä¼°

```
æ•´ä½“å®Œæˆåº¦: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 35%

è¯¦ç»†è¯„åˆ†:
- è®­ç»ƒæµç¨‹:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 80%
- æŸå¤±å¯è§†åŒ–:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 80%  
- è¡¨å¾åˆ†æ:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 40%
- å™ªå£°é²æ£’æ€§:   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0%
- å¯¹é½æ€§åˆ†æ:   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 20%
- å‡åŒ€æ€§åˆ†æ:   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0%
- åŸºçº¿å¯¹æ¯”:     â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0%
```

---

## ğŸ“ ä¸ƒã€å·²ç”Ÿæˆçš„ç¤ºä¾‹å›¾è¡¨

æœ¬æ¬¡åˆ†æå·²ç”Ÿæˆä»¥ä¸‹è®ºæ–‡é£æ ¼çš„ç¤ºä¾‹å›¾è¡¨:

1. `figure2_noise_robustness.png` - å™ªå£°é²æ£’æ€§å¯¹æ¯” (Figure 2é£æ ¼)
2. `figure5_alignment_analysis.png` - å¯¹é½æ€§åˆ†æ (Figure 5é£æ ¼)
3. `figure6_uniformity_coinception.png` - å‡åŒ€æ€§åˆ†æ (Figure 6é£æ ¼)
4. `figure8_noise_ratio.png` - å™ªå£°æ¯”ä¾‹åˆ†æé›·è¾¾å›¾ (Figure 8é£æ ¼)
5. `figure13_receptive_field.png` - æ„Ÿå—é‡åˆ†æ (Figure 13é£æ ¼)
6. `figure14_clusterability_StarLightCurves.png` - èšç±»æ€§åˆ†æ (Figure 14é£æ ¼)

**æ³¨æ„:** è¿™äº›å›¾è¡¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆï¼Œä»…å±•ç¤ºè®ºæ–‡è¦æ±‚çš„å›¾è¡¨æ ¼å¼ã€‚å®é™…å¤ç°éœ€è¦ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®ã€‚

---

## âœ… å…«ã€ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ¸…å•

- [ ] ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼Œä¿å­˜æ ·æœ¬æ ‡ç­¾ä¿¡æ¯
- [ ] å®ç°å™ªå£°é²æ£’æ€§æµ‹è¯•å‡½æ•°
- [ ] é‡æ–°è®­ç»ƒå¹¶ä¿å­˜å¸¦æ ‡ç­¾çš„è¡¨å¾
- [ ] ç”ŸæˆFigure 2å™ªå£°é²æ£’æ€§å¯¹æ¯”å›¾
- [ ] ä¿®æ­£t-SNEå¯è§†åŒ–ï¼Œä½¿ç”¨ç±»åˆ«ç€è‰²
- [ ] å°†ä½™å¼¦ç›¸ä¼¼åº¦æ”¹ä¸ºL2è·ç¦»åˆ†æ
- [ ] æ·»åŠ KDEå¯†åº¦ä¼°è®¡å¯è§†åŒ–
- [ ] (å¯é€‰) è¿è¡ŒTS2Vecè·å–åŸºçº¿å¯¹æ¯”æ•°æ®

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2024*
*åˆ†æå·¥å…·: CoInception Visualization Optimizer*
